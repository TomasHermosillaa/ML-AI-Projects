
# SegmentaciÃ³n y Conteo de NÃºcleos Celulares - Proyecto ML End-to-End
TomÃ¡s Hermosilla - 2025

Sistema completo de **segmentaciÃ³n y conteo automÃ¡tico de cÃ©lulas** usando **U-Net** desde cero.

## Objetivo del Proyecto COMPLETADO

Sistema completo de segmentaciÃ³n y conteo que:
- âœ… **Identifica y delimita nÃºcleos individuales** en imÃ¡genes microscÃ³picas
- âœ… **Cuenta cÃ©lulas automÃ¡ticamente** con 78.3% de precisiÃ³n
- âœ… **Segmenta con 89.82% Dice Score** y 95.31% de precisiÃ³n 
- âœ… **Procesa imÃ¡genes biomÃ©dicas** con tÃ©cnicas de normalizaciÃ³n avanzadas
- âœ… **Pipeline end-to-end funcional**: Imagen â†’ SegmentaciÃ³n â†’ Conteo

## Resultados Principales

### Rendimiento del Modelo
- **Dice Score**: 89.82% (excelente precisiÃ³n de segmentaciÃ³n)
- **IoU**: 81.53% (alta superposiciÃ³n con ground truth)
- **Precision**: 95.31% (muy pocas falsas detecciones)
- **Recall**: 84.93% (detecta la mayorÃ­a de nÃºcleos)

### Conteo de CÃ©lulas
- **MÃ©todo Ã³ptimo**: Componentes conectados simples
- **PrecisiÃ³n de conteo**: 78.3% (18/23 cÃ©lulas detectadas)
- **Error promedio**: Â±5 cÃ©lulas por imagen
- **MÃ©todos implementados**: Simple, Watershed, Distance Transform

---

## Estructura del Proyecto

```
ML-AI-Projects/
â”œâ”€â”€ data/                           # Dataset DSB2018 (2,224 muestras)
â”‚   â”œâ”€â”€ 00001/
â”‚   â”‚   â”œâ”€â”€ image.png              # Imagen RGB microscÃ³pica
â”‚   â”‚   â””â”€â”€ mask.png               # MÃ¡scara binaria consolidada
â”‚   â”œâ”€â”€ 00002/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                           # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ nuclei_dataset.py          # Dataset PyTorch personalizado
â”‚   â”œâ”€â”€ normalization.py           # TÃ©cnicas de normalizaciÃ³n biomÃ©dica
â”‚   â”œâ”€â”€ conv_blocks.py             # Arquitectura U-Net desde cero
â”‚   â”œâ”€â”€ train.py                   # Script de entrenamiento completo
â”‚   â””â”€â”€ inference.py               # PredicciÃ³n y conteo de cÃ©lulas
â”œâ”€â”€ notebooks/                     # AnÃ¡lisis y experimentaciÃ³n
â”‚   â”œâ”€â”€ exploratory_analysis.ipynb     # EDA del dataset
â”‚   â”œâ”€â”€ morphological_operations.ipynb # Operaciones morfolÃ³gicas
â”‚   â”œâ”€â”€ normalization_techniques.ipynb # ComparaciÃ³n de normalizaciones
â”‚   â””â”€â”€ weight_maps_analysis.ipynb     # AnÃ¡lisis de mapas de peso
â”œâ”€â”€ tests/                         # Scripts de prueba y validaciÃ³n
â”‚   â”œâ”€â”€ test_nuclei_dataset.py     # ValidaciÃ³n completa del dataset
â”‚   â”œâ”€â”€ verify_installation.py     # VerificaciÃ³n del entorno
â”‚   â””â”€â”€ analyze_dataset.py         # AnÃ¡lisis estadÃ­stico del dataset
â”œâ”€â”€ plan/                          # DocumentaciÃ³n del proyecto
â”‚   â”œâ”€â”€ Plan_Detallado_Segmentacion_Nucleos.md
â”‚   â”œâ”€â”€ analisis_exploratorio_dataset.md
â”‚   â”œâ”€â”€ analisis_normalizacion_imagenes.md
â”‚   â””â”€â”€ analisis_mapas_peso.md
â”œâ”€â”€ examples/                      # Ejemplos y visualizaciones
â”‚   â”œâ”€â”€ dataset_examples.png
â”‚   â””â”€â”€ dataset_analysis.csv
â”œâ”€â”€ images/                        # ImÃ¡genes generadas por anÃ¡lisis
â”‚   â”œâ”€â”€ dataset_validation_sample.png
â”‚   â”œâ”€â”€ image-stats.png
â”‚   â””â”€â”€ image-weight.png
â”œâ”€â”€ unet_nuclei.pth                # Modelo entrenado listo para uso
â”œâ”€â”€ cell_counting_result.png       # VisualizaciÃ³n de conteo de cÃ©lulas
â”œâ”€â”€ prediction_result.png          # Resultado de predicciÃ³n
â”œâ”€â”€ venv/                          # Entorno virtual Python
â”œâ”€â”€ requirements.txt               # Dependencias del proyecto
â””â”€â”€ README.md                      # Este archivo
```

---

## ConfiguraciÃ³n del Entorno

### 1. Prerrequisitos
- **Python 3.8+**
- **CUDA 12.1+** (para GPU)
- **8GB+ VRAM** recomendado

### 2. InstalaciÃ³n Paso a Paso

```bash
# 1. Clonar y acceder al proyecto
cd /path/to/ML-AI-Projects

# 2. Crear entorno virtual
python -m venv venv

# 3. Activar entorno virtual
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 4. Verificar CUDA (opcional pero recomendado)
nvidia-smi

# 5. Instalar PyTorch con soporte CUDA
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# 6. Instalar dependencias adicionales
pip install -r requirements.txt

# 7. Verificar instalaciÃ³n
python tests/verify_installation.py
```

### 3. Configurar Jupyter (Opcional)
```bash
python -m ipykernel install --user --name=nuclei_segmentation --display-name="Nuclei Segmentation"
jupyter lab --no-browser --port=8888
```

---

## Dataset (DSB2018)

### PreparaciÃ³n
1. **Descargar** dataset desde Kaggle: `2018 Data Science Bowl`
2. **Descomprimir** en carpeta `data/`
3. **Verificar** estructura:

```bash
python tests/analyze_dataset.py
```

### CaracterÃ­sticas del Dataset
- **2,224 muestras** - Robusto para entrenamiento
- **Dimensiones fijas**: 256Ã—256 pÃ­xeles
- **MÃ¡scaras binarias**: NÃºcleos consolidados (0=fondo, 255=nÃºcleo)
- **Desbalance de clases**: 12.2% nÃºcleos vs 87.8% fondo
- **Variedad**: Diferentes tÃ©cnicas de tinciÃ³n y tipos celulares

---

## Componentes Implementados

### Etapa 1: AnÃ¡lisis Exploratorio
- **EDA completo** del dataset DSB2018
- **Visualizaciones** estadÃ­sticas de distribuciones
- **IdentificaciÃ³n** de patrones y desafÃ­os
- **AnÃ¡lisis** de calidad de mÃ¡scaras

### Etapa 2: IngenierÃ­a de Datos

#### TÃ©cnicas de NormalizaciÃ³n (`src/normalization.py`)
```python
from src.normalization import normalize_per_channel, normalize_clahe

# NormalizaciÃ³n por canal (recomendada)
normalized = normalize_per_channel(image)

# CLAHE + CorrecciÃ³n Gamma para contraste
enhanced = normalize_clahe(image, clip_limit=2.0)
```

#### Mapas de Peso MorfolÃ³gicos (`src/weight_maps.py`)
```python
from src.weight_maps import create_edge_weight_map

# Generar mapa que enfatiza bordes entre nÃºcleos
weight_map, edges = create_edge_weight_map(mask, edge_weight=5.0)
```

#### Dataset PyTorch (`src/nuclei_dataset.py`)
```python
from src.nuclei_dataset import NucleiDataset
from torch.utils.data import DataLoader

# Crear dataset con configuraciÃ³n avanzada
dataset = NucleiDataset(
    data_root="data",
    normalization_method='per_channel',
    generate_weight_maps=True,
    image_size=(256, 256)
)

# DataLoader para entrenamiento
loader = DataLoader(dataset, batch_size=4, shuffle=True)
```

### Etapa 3: Arquitectura U-Net
```python
from src.conv_blocks import BasicUNet

# Modelo U-Net desde cero con 24M parÃ¡metros
model = BasicUNet(in_channels=3, out_channels=1)
print(f"ParÃ¡metros totales: {sum(p.numel() for p in model.parameters()):,}")
```

### Etapa 4: Entrenamiento Completo
```bash
# Entrenar el modelo (configurado para GPU)
python -m src.train

# Resultados obtenidos:
# - 91% Dice Score final
# - Convergencia en 25 Ã©pocas
# - Modelo guardado en unet_nuclei.pth
```

### Etapa 5: Conteo de CÃ©lulas
```python
from src.inference import NucleiPredictor

# Cargar modelo entrenado
predictor = NucleiPredictor("unet_nuclei.pth")

# Hacer predicciÃ³n y conteo
result = predictor.predict_from_path("imagen.png")
count_result = predictor.count_cells(result['binary_mask'])

print(f"CÃ©lulas detectadas: {count_result['count']}")
# Salida: CÃ©lulas detectadas: 18
```

---

## Pruebas y ValidaciÃ³n

### Ejecutar Todas las Pruebas
```bash
# Prueba completa del dataset (recomendado)
python tests/test_nuclei_dataset.py

# AnÃ¡lisis del dataset
python tests/analyze_dataset.py

# Verificar instalaciones
python tests/verify_installation.py
```

### Explorar con Notebooks
```bash
jupyter lab

# Navegar a:
# - notebooks/exploratory_analysis.ipynb
# - notebooks/morphological_operations.ipynb  
# - notebooks/normalization_techniques.ipynb
```

## Especificaciones TÃ©cnicas

### Tensores del Dataset
```python
# Salida tÃ­pica de NucleiDataset[i]
sample = {
    'image': torch.Tensor,      # Shape: (3, 256, 256), dtype: float32
    'mask': torch.Tensor,       # Shape: (256, 256), dtype: float32, rango: [0, 1]  
    'weight_map': torch.Tensor, # Shape: (256, 256), dtype: float32, rango: [0.1, 5.0]
    'sample_id': str            # ID de la muestra: "00001", "00002", etc.
}

# Batch del DataLoader
batch = {
    'image': torch.Tensor,      # Shape: (B, 3, 256, 256)
    'mask': torch.Tensor,       # Shape: (B, 256, 256)
    'weight_map': torch.Tensor, # Shape: (B, 256, 256)
    'sample_id': List[str]      # Lista de IDs del batch
}
```

### Mapas de Peso
- **Fondo**: 0.1 (peso bajo)
- **NÃºcleos**: 1.0 (peso normal)
- **Bordes**: 5.0 (peso alto - Ã©nfasis en separaciÃ³n)
- **Promedio de bordes**: ~6.18% de pÃ­xeles por imagen

### MÃ©todos de NormalizaciÃ³n
- **`per_channel`**: Media=0, STD=1 por canal RGB â­ **Recomendada**
- **`clahe_gamma`**: CLAHE + correcciÃ³n gamma para contraste
- **`none`**: Escalado simple a [0, 1]


## Uso RÃ¡pido del Sistema Completo

### Entrenar el Modelo
```bash
# Entrenar desde cero (requiere GPU recomendado)
python -m src.train

# Resultados esperados:
# - Dice Score: ~90%
# - Modelo guardado: unet_nuclei.pth
```

### Conteo de CÃ©lulas en Nueva Imagen
```python
from src.inference import NucleiPredictor

# 1. Cargar modelo entrenado
predictor = NucleiPredictor("unet_nuclei.pth")

# 2. Procesar imagen y contar cÃ©lulas
result = predictor.predict_from_path("mi_imagen.png")
count_result = predictor.count_cells(result['binary_mask'])

print(f"ğŸ”¬ CÃ©lulas detectadas: {count_result['count']}")
print(f"ğŸ“Š Ãrea promedio: {np.mean([p.area for p in count_result['cell_properties']]):.1f} pÃ­xeles")

# 3. Visualizar resultados (se guarda automÃ¡ticamente)
# Las visualizaciones se guardan en cell_counting_result.png
```

### Pipeline Completo de Datos
```python
from src.nuclei_dataset import NucleiDataset
from torch.utils.data import DataLoader

# Dataset con todas las configuraciones optimizadas
dataset = NucleiDataset(
    data_root="data", 
    normalization_method='per_channel',
    generate_weight_maps=True
)

# Listo para entrenamiento
loader = DataLoader(dataset, batch_size=4, shuffle=True)
```

---

## InformaciÃ³n de Contacto

**Autor**: TomÃ¡s Hermosilla
**Contacto**: tomas.hermosilla.p@gmail.com 

---

## Licencia

Este proyecto abierto es de propÃ³sito educativo y de investigaciÃ³n.