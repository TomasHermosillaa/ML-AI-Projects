
# ğŸ”¬ SegmentaciÃ³n de NÃºcleos Celulares - Proyecto ML End-to-End
TomÃ¡s Hermosilla - 2025
Proyecto de **segmentaciÃ³n de instancias de nÃºcleos celulares** usando **Deep Learning** con arquitectura U-Net implementada desde cero. Incluye pipeline completo de ingenierÃ­a de datos, entrenamiento y despliegue.

## ğŸ¯ Objetivo del Proyecto

Desarrollar un sistema completo de segmentaciÃ³n que pueda:
- Identificar y delimitar nÃºcleos individuales en imÃ¡genes microscÃ³picas
- Separar nÃºcleos que se tocan usando mapas de peso morfolÃ³gicos
- Procesar imÃ¡genes biomÃ©dicas con diferentes tÃ©cnicas de tinciÃ³n
- Proporcionar mÃ¡scaras precisas para anÃ¡lisis posterior

---

## ğŸ“ Estructura del Proyecto

```
ML-AI-Projects/
â”œâ”€â”€ data/                           # Dataset DSB2018 (2,224 muestras)
â”‚   â”œâ”€â”€ 00001/
â”‚   â”‚   â”œâ”€â”€ image.png              # Imagen RGB microscÃ³pica
â”‚   â”‚   â””â”€â”€ mask.png               # MÃ¡scara binaria consolidada
â”‚   â”œâ”€â”€ 00002/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                           # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ nuclei_dataset.py          # Dataset PyTorch personalizado
â”‚   â”œâ”€â”€ normalization.py           # TÃ©cnicas de normalizaciÃ³n biomÃ©dica
â”‚   â””â”€â”€ weight_maps.py            # GeneraciÃ³n de mapas de peso morfolÃ³gicos
â”œâ”€â”€ notebooks/                     # AnÃ¡lisis y experimentaciÃ³n
â”‚   â”œâ”€â”€ exploratory_analysis.ipynb     # EDA del dataset
â”‚   â”œâ”€â”€ morphological_operations.ipynb # Operaciones morfolÃ³gicas
â”‚   â”œâ”€â”€ normalization_techniques.ipynb # ComparaciÃ³n de normalizaciones
â”‚   â””â”€â”€ weight_maps_analysis.ipynb     # AnÃ¡lisis de mapas de peso
â”œâ”€â”€ tests/                         # Scripts de prueba y validaciÃ³n
â”‚   â”œâ”€â”€ test_nuclei_dataset.py     # ValidaciÃ³n completa del dataset
â”‚   â”œâ”€â”€ verify_installation.py     # VerificaciÃ³n del entorno
â”‚   â””â”€â”€ analyze_dataset.py         # AnÃ¡lisis estadÃ­stico del dataset
â”œâ”€â”€ plan/                          # DocumentaciÃ³n del proyecto
â”‚   â”œâ”€â”€ Plan_Detallado_Segmentacion_Nucleos.md
â”‚   â”œâ”€â”€ analisis_exploratorio_dataset.md
â”‚   â”œâ”€â”€ analisis_normalizacion_imagenes.md
â”‚   â””â”€â”€ analisis_mapas_peso.md
â”œâ”€â”€ examples/                      # Ejemplos y visualizaciones
â”‚   â”œâ”€â”€ dataset_examples.png
â”‚   â””â”€â”€ dataset_analysis.csv
â”œâ”€â”€ images/                        # ImÃ¡genes generadas por anÃ¡lisis
â”‚   â”œâ”€â”€ dataset_validation_sample.png
â”‚   â”œâ”€â”€ image-stats.png
â”‚   â””â”€â”€ image-weight.png
â”œâ”€â”€ venv/                          # Entorno virtual Python
â”œâ”€â”€ requirements.txt               # Dependencias del proyecto
â””â”€â”€ README.md                      # Este archivo
```

---

## ğŸ› ï¸ ConfiguraciÃ³n del Entorno

### 1. Prerrequisitos
- **Python 3.8+**
- **CUDA 12.1+** (para GPU)
- **8GB+ VRAM** recomendado

### 2. InstalaciÃ³n Paso a Paso

```bash
# 1. Clonar y acceder al proyecto
cd /path/to/ML-AI-Projects

# 2. Crear entorno virtual
python -m venv venv

# 3. Activar entorno virtual
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 4. Verificar CUDA (opcional pero recomendado)
nvidia-smi

# 5. Instalar PyTorch con soporte CUDA
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# 6. Instalar dependencias adicionales
pip install -r requirements.txt

# 7. Verificar instalaciÃ³n
python tests/verify_installation.py
```

### 3. Configurar Jupyter (Opcional)
```bash
python -m ipykernel install --user --name=nuclei_segmentation --display-name="Nuclei Segmentation"
jupyter lab --no-browser --port=8888
```

---

## ğŸ“š Dataset (DSB2018)

### PreparaciÃ³n
1. **Descargar** dataset desde Kaggle: `2018 Data Science Bowl`
2. **Descomprimir** en carpeta `data/`
3. **Verificar** estructura:

```bash
python tests/analyze_dataset.py
```

### CaracterÃ­sticas del Dataset
- **ğŸ“Š 2,224 muestras** - Robusto para entrenamiento
- **ğŸ–¼ï¸ Dimensiones fijas**: 256Ã—256 pÃ­xeles
- **ğŸ¯ MÃ¡scaras binarias**: NÃºcleos consolidados (0=fondo, 255=nÃºcleo)
- **âš–ï¸ Desbalance de clases**: 12.2% nÃºcleos vs 87.8% fondo
- **ğŸ”¬ Variedad**: Diferentes tÃ©cnicas de tinciÃ³n y tipos celulares

---

## ğŸ”§ Componentes Implementados

### ğŸ“Š **Etapa 1: AnÃ¡lisis Exploratorio** âœ…
- **EDA completo** del dataset DSB2018
- **Visualizaciones** estadÃ­sticas de distribuciones
- **IdentificaciÃ³n** de patrones y desafÃ­os
- **AnÃ¡lisis** de calidad de mÃ¡scaras

### ğŸ› ï¸ **Etapa 2: IngenierÃ­a de Datos** âœ…

#### TÃ©cnicas de NormalizaciÃ³n (`src/normalization.py`)
```python
from src.normalization import normalize_per_channel, normalize_clahe

# NormalizaciÃ³n por canal (recomendada)
normalized = normalize_per_channel(image)

# CLAHE + CorrecciÃ³n Gamma para contraste
enhanced = normalize_clahe(image, clip_limit=2.0)
```

#### Mapas de Peso MorfolÃ³gicos (`src/weight_maps.py`)
```python
from src.weight_maps import create_edge_weight_map

# Generar mapa que enfatiza bordes entre nÃºcleos
weight_map, edges = create_edge_weight_map(mask, edge_weight=5.0)
```

#### Dataset PyTorch (`src/nuclei_dataset.py`)
```python
from src.nuclei_dataset import NucleiDataset
from torch.utils.data import DataLoader

# Crear dataset con configuraciÃ³n avanzada
dataset = NucleiDataset(
    data_root="data",
    normalization_method='per_channel',
    generate_weight_maps=True,
    image_size=(256, 256)
)

# DataLoader para entrenamiento
loader = DataLoader(dataset, batch_size=4, shuffle=True)
```

---

## ğŸ§ª Pruebas y ValidaciÃ³n

### Ejecutar Todas las Pruebas
```bash
# Prueba completa del dataset (recomendado)
python tests/test_nuclei_dataset.py

# AnÃ¡lisis del dataset
python tests/analyze_dataset.py

# Verificar instalaciones
python tests/verify_installation.py
```

### Explorar con Notebooks
```bash
jupyter lab

# Navegar a:
# - notebooks/exploratory_analysis.ipynb
# - notebooks/morphological_operations.ipynb  
# - notebooks/normalization_techniques.ipynb
```

---

## ğŸ“ˆ Estado Actual del Desarrollo

### âœ… **Completado**
- [x] **AnÃ¡lisis exploratorio** completo del dataset
- [x] **6 tÃ©cnicas de normalizaciÃ³n** implementadas y comparadas
- [x] **Mapas de peso morfolÃ³gicos** con gradiente morfolÃ³gico
- [x] **Dataset PyTorch personalizado** con lazy loading
- [x] **Pipeline de datos completo** validado con 2,224 muestras
- [x] **Pruebas automatizadas** con cobertura del 100%

### ğŸ”„ **En Progreso**
- [ ] Arquitectura U-Net desde cero
- [ ] Bloques convolucionales modulares
- [ ] Skip connections optimizadas

### ğŸ“‹ **PrÃ³ximos Pasos**
1. **Arquitectura Neural BÃ¡sica** (Etapa 3)
2. **FunciÃ³n de PÃ©rdida DiceBCE** (Etapa 4)
3. **Loop de Entrenamiento** con AMP (Etapa 5)
4. **Post-procesamiento Watershed** (Etapa 6)

---

## ğŸ¯ Especificaciones TÃ©cnicas

### Tensores del Dataset
```python
# Salida tÃ­pica de NucleiDataset[i]
sample = {
    'image': torch.Tensor,      # Shape: (3, 256, 256), dtype: float32
    'mask': torch.Tensor,       # Shape: (256, 256), dtype: float32, rango: [0, 1]  
    'weight_map': torch.Tensor, # Shape: (256, 256), dtype: float32, rango: [0.1, 5.0]
    'sample_id': str            # ID de la muestra: "00001", "00002", etc.
}

# Batch del DataLoader
batch = {
    'image': torch.Tensor,      # Shape: (B, 3, 256, 256)
    'mask': torch.Tensor,       # Shape: (B, 256, 256)
    'weight_map': torch.Tensor, # Shape: (B, 256, 256)
    'sample_id': List[str]      # Lista de IDs del batch
}
```

### Mapas de Peso
- **Fondo**: 0.1 (peso bajo)
- **NÃºcleos**: 1.0 (peso normal)
- **Bordes**: 5.0 (peso alto - Ã©nfasis en separaciÃ³n)
- **Promedio de bordes**: ~6.18% de pÃ­xeles por imagen

### MÃ©todos de NormalizaciÃ³n
- **`per_channel`**: Media=0, STD=1 por canal RGB â­ **Recomendada**
- **`clahe_gamma`**: CLAHE + correcciÃ³n gamma para contraste
- **`none`**: Escalado simple a [0, 1]

---

## ğŸš€ Uso RÃ¡pido

```python
# Ejemplo completo de uso del dataset
from src.nuclei_dataset import NucleiDataset, create_data_loaders
import matplotlib.pyplot as plt

# 1. Crear dataset
dataset = NucleiDataset("data", generate_weight_maps=True)
print(f"Dataset cargado: {len(dataset)} muestras")

# 2. Obtener una muestra
sample = dataset[0]
print(f"Imagen: {sample['image'].shape}")
print(f"MÃ¡scara: {sample['mask'].shape}")  
print(f"Pesos: {sample['weight_map'].shape}")

# 3. Crear DataLoaders
train_loader, val_loader = create_data_loaders("data", batch_size=4)

# 4. Iterar sobre batches
for batch in train_loader:
    images = batch['image']      # (4, 3, 256, 256)
    masks = batch['mask']        # (4, 256, 256)
    weights = batch['weight_map'] # (4, 256, 256)
    break
```

---

## ğŸ“ InformaciÃ³n de Contacto

**Autor**: TomÃ¡s Hermosilla
**Contacto**: tomas.hermosilla.p@gmail.com 

---

## ğŸ“œ Licencia

Este proyecto abierto es de propÃ³sito educativo y de investigaciÃ³n.